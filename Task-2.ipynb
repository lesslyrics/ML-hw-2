{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-10 00:45:42--  https://archive.org/download/nf_prize_dataset.tar/nf_prize_dataset.tar.gz\n",
      "Resolving archive.org (archive.org)... 207.241.224.2\n",
      "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ia600205.us.archive.org/7/items/nf_prize_dataset.tar/nf_prize_dataset.tar.gz [following]\n",
      "--2021-11-10 00:45:43--  https://ia600205.us.archive.org/7/items/nf_prize_dataset.tar/nf_prize_dataset.tar.gz\n",
      "Resolving ia600205.us.archive.org (ia600205.us.archive.org)... 207.241.227.225\n",
      "Connecting to ia600205.us.archive.org (ia600205.us.archive.org)|207.241.227.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 697552028 (665M) [application/octet-stream]\n",
      "Saving to: ‘nf_prize_dataset.tar.gz’\n",
      "\n",
      "nf_prize_dataset.ta 100%[===================>] 665,24M   672KB/s    in 44m 49s \n",
      "\n",
      "2021-11-10 01:30:33 (253 KB/s) - ‘nf_prize_dataset.tar.gz’ saved [697552028/697552028]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "!wget https://archive.org/download/nf_prize_dataset.tar/nf_prize_dataset.tar.gz\n",
    "!tar -xzf nf_prize_dataset.tar.gz\n",
    "!tar -xf download/training_set.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  14759, 1124804,       4],\n",
       "       [   3579,  415594,       4],\n",
       "       [  10491, 1616888,       5],\n",
       "       [  13255,  137051,       4],\n",
       "       [  14574,  960577,       4]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import trange\n",
    "\n",
    "entries = np.zeros((100480507, 3), dtype = int)\n",
    "\n",
    "training_set = 'training_set/'\n",
    "i = 0\n",
    "\n",
    "for filename in os.listdir(training_set):\n",
    "    file = training_set + filename\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        movie_id = int(lines[0].split(':')[0])\n",
    "        for line in lines[1:]:\n",
    "            user_id, user_score, date = line.split(',')\n",
    "            user_id, user_score = int(user_id), int(user_score)\n",
    "            entries[i] = movie_id, user_id, user_score\n",
    "            i+=1\n",
    "\n",
    "# shuffle \n",
    "entries = entries[np.random.permutation(len(entries))]\n",
    "entries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "user_ids = {x:i for i,x in enumerate(set(entries[:, 1]))} # create user ids list\n",
    "\n",
    "movies_number = 17770\n",
    "users_number = len(user_ids)\n",
    "\n",
    "x = np.zeros((entries.shape[0], 2))\n",
    "\n",
    "# movie id, translate to [0, MOVIES_NUM-1]\n",
    "x[:, 0] = entries[:, 0] - 1\n",
    "\n",
    "# user id, translate to [0, size NUMBER_OF_USERS-1], offset by MOVIES_NUM\n",
    "x[:, 1] = movies_number + np.vectorize(user_ids.get)(entries[:, 1])\n",
    "\n",
    "# for indexing\n",
    "x = x.astype(int)\n",
    "\n",
    "# rating\n",
    "y = entries[:, 2]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation\n",
    "\n",
    "class KFoldsValidation:\n",
    "    def __init__(self, x, y, folds_num = 5):\n",
    "        fold_range = range(folds_num)\n",
    "        self.folds_num = folds_num\n",
    "        self.x_folds = [x[i::folds_num] for i in fold_range]\n",
    "        self.y_folds = [y[i::folds_num] for i in fold_range]\n",
    "        \n",
    "    def get(self, fold_i):\n",
    "        fold_range = range(self.folds_num)\n",
    "        \n",
    "        x_fold = self.x_folds[fold_i]\n",
    "        y_fold = self.y_folds[fold_i]\n",
    "        \n",
    "        # remove current fold from train set        \n",
    "        x_train = np.concatenate([self.x_folds[i] for i in fold_range if i != fold_i])\n",
    "        y_train = np.concatenate([self.y_folds[i] for i in fold_range if i != fold_i])\n",
    "        \n",
    "        return x_train, y_train, x_fold, y_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_score(y_true, y_pred):\n",
    "    return np.mean(np.square(y_true - y_pred))**0.5\n",
    "\n",
    "def r2_score(y, y_pred):\n",
    "    y_avg = y.mean()\n",
    "    ss_total = np.sum(np.square(y - y_avg))\n",
    "    ss_err = np.sum(np.square(y - y_pred))\n",
    "    return (1 - ss_err/ss_total)\n",
    "\n",
    "\n",
    "# reference for Adam: https://ruder.io/optimizing-gradient-descent/index.html#challenges\n",
    "class FactorizationMachine: #todo\n",
    "    def __init__(self, n, k):\n",
    "            \n",
    "        self.t = 0\n",
    "        self.eps = 1e-8\n",
    "        self.lr = 0.01\n",
    "        \n",
    "        # adam hyperparams, decay rates\n",
    "        self.beta_1 = 0.9\n",
    "        self.beta_2 = 0.999\n",
    "        \n",
    "        self.w_0 = 0\n",
    "        self.w = 0.01 * np.random.randn(n)\n",
    "        self.v = 0.01 * np.random.randn(n,k)\n",
    "\n",
    "        # adam moments\n",
    "        self.v_dw_0 = np.zeros_like(self.w_0)\n",
    "        self.s_dw_0 = np.zeros_like(self.w_0)\n",
    "        self.v_dw = np.zeros_like(self.w)\n",
    "        self.s_dw = np.zeros_like(self.w)\n",
    "        self.v_dv = np.zeros_like(self.v)\n",
    "        self.s_dv = np.zeros_like(self.v)\n",
    "\n",
    "        # cache to be used in backward pass\n",
    "        self.x_batch = None\n",
    "        self.v_dot_x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        n = total_features\n",
    "        k = 3\n",
    "        \n",
    "\n",
    "        # cache\n",
    "        self.x_batch = x\n",
    "        self.v_dot_x = np.sum(self.v[x], axis=1)\n",
    "        \n",
    "        return self.w_0   \\\n",
    "               + np.sum(self.w[x], axis=1)   \\\n",
    "               + 0.5 * np.sum(np.square(self.v_dot_x) - np.sum(np.square(self.v[x]), axis=1), axis=1)\n",
    "         \n",
    "    def backward(self, dLdy):\n",
    "        \n",
    "        n = total_features\n",
    "        k = 3\n",
    "        \n",
    "        if self.x_batch is None:\n",
    "            assert 0, 'Call forward first'\n",
    "\n",
    "        #Gradient w.r.t. bias\n",
    "        dLdw_0 = np.mean(dLdy)\n",
    "\n",
    "        #Gradient w.r.t. linear weights\n",
    "        dLdw = np.zeros(n)\n",
    "        for x, dLdyi in zip(self.x_batch, dLdy):\n",
    "            dLdw[x] +=  dLdyi\n",
    "        dLdw /= dLdy.shape[0]\n",
    "\n",
    "        #Gradient w.r.t. pairwise weights\n",
    "        dLdv = np.zeros((n,k))\n",
    "        for x, v_dot_xi, dLdyi in zip(self.x_batch, self.v_dot_x, dLdy):\n",
    "            dLdv[x] += dLdyi * (v_dot_xi - self.v[x])\n",
    "        dLdv /= dLdy.shape[0]\n",
    "\n",
    "        # estimate moments\n",
    "        # compute the decaying averages of past and past squared gradients \n",
    "        self.v_dw_0 = self.beta_1 * self.v_dw_0 + (1 - self.beta_1) * dLdw_0\n",
    "        self.s_dw_0 = self.beta_2 * self.s_dw_0 + (1 - self.beta_2) * dLdw_0 * dLdw_0\n",
    "        \n",
    "        self.v_dw = self.beta_1 * self.v_dw + (1 - self.beta_1) * dLdw\n",
    "        self.s_dw = self.beta_2 * self.s_dw + (1 - self.beta_2) * dLdw * dLdw\n",
    "        \n",
    "        self.v_dv = self.beta_1 * self.v_dv + (1 - self.beta_1) * dLdv\n",
    "        self.s_dv = self.beta_2 * self.s_dv + (1 - self.beta_2) * dLdv * dLdv\n",
    "        \n",
    "        # computing bias-corrected first and second moment estimates\n",
    "        self.t += 1\n",
    "        bias_correction_1 = 1 - self.beta_1**self.t\n",
    "        bias_correction_2 = 1 - self.beta_2**self.t\n",
    "\n",
    "        step_size = self.lr / bias_correction_1\n",
    "\n",
    "        denom_dw_0 = np.sqrt(self.s_dw_0) / math.sqrt(bias_correction_2) + self.eps\n",
    "        denom_dw = np.sqrt(self.s_dw) / math.sqrt(bias_correction_2) + self.eps\n",
    "        denom_dv = np.sqrt(self.s_dv) / math.sqrt(bias_correction_2) + self.eps\n",
    "\n",
    "        # Adam update rule\n",
    "        self.w_0 -= step_size * self.v_dw_0 / denom_dw_0\n",
    "        self.w -= step_size * self.v_dw / denom_dw\n",
    "        self.v -= step_size * self.v_dv / denom_dv\n",
    "        \n",
    "        #Clear cache\n",
    "        self.v_dot_x = None\n",
    "        self.x_batch = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error estimation\n",
    "class MSE:\n",
    "    def __init__(self):\n",
    "        self.error = None\n",
    "        \n",
    "    def forward(self, y_true, y_predicted):\n",
    "        self.error = y_true - y_predicted\n",
    "        return np.mean(np.square(self.error))\n",
    "    \n",
    "    def backward(self):\n",
    "        if self.error is None:\n",
    "            assert 0, 'Call forward first'\n",
    "        return self.error * -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_features = users_number + movies_number\n",
    "\n",
    "kfold = KFoldsValidation(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20000\n",
    "\n",
    "def get_batch(x,y, i):\n",
    "    return x[i * batch_size:(i + 1) * batch_size], y[i * batch_size:(i + 1) * batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4020 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train on fold 1\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4020/4020 [13:38<00:00,  4.91it/s, mse=0.778, r2=0.325]\n",
      "  1%|▏         | 14/1005 [00:00<00:07, 131.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE = 1.0476009468915124, R2 = 0.11059035189765729\n",
      " Test on 1 fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1005/1005 [00:07<00:00, 133.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE = 0.8878679139505763, R2 = 0.330452550020646\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4020 [00:00<13:20,  5.02it/s, mse=14, r2=-10.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train on fold 2\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4020/4020 [13:10<00:00,  5.08it/s, mse=0.782, r2=0.322]\n",
      "  1%|          | 10/1005 [00:00<00:10, 91.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE = 1.0558914858534199, R2 = 0.10351467351799043\n",
      " Test on 2 fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1005/1005 [00:13<00:00, 77.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE = 0.8930051545504788, R2 = 0.32281649425616543\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4020 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train on fold 3\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4020/4020 [14:36<00:00,  4.58it/s, mse=0.781, r2=0.324]\n",
      "  1%|▏         | 15/1005 [00:00<00:07, 141.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE = 1.0499099829725316, R2 = 0.10854741023798724\n",
      " Test on 3 fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1005/1005 [00:07<00:00, 136.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE = 0.8905267297231604, R2 = 0.32673754097467345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4020 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train on fold 4\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4020/4020 [13:31<00:00,  4.95it/s, mse=0.784, r2=0.321]\n",
      "  1%|▏         | 14/1005 [00:00<00:07, 135.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE = 1.0542051840635778, R2 = 0.10491074414943645\n",
      " Test on 4 fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1005/1005 [00:07<00:00, 133.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE = 0.8892306975627016, R2 = 0.3286516330017323\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4020 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train on fold 5\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4020/4020 [13:25<00:00,  4.99it/s, mse=0.791, r2=0.331]\n",
      "  1%|▏         | 14/1005 [00:00<00:07, 131.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE = 1.0527461040150123, R2 = 0.10615971659362171\n",
      " Test on 5 fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1005/1005 [00:07<00:00, 134.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE = 0.8901148970730431, R2 = 0.32729048514378944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "\n",
    "def compute_with_factorization_machine(epochs, n_movies, n_users, k):\n",
    "    \n",
    "    rmses = []\n",
    "    r2s = []\n",
    "    \n",
    "    n = n_movies + n_users\n",
    "    criterion = MSE()\n",
    "    \n",
    "    for fold_i in range(kfold.folds_num):\n",
    "        model = FactorizationMachine(n,k)    \n",
    "        X_train, y_train, X_test, y_test = kfold.get(fold_i)\n",
    "\n",
    "        #TRAIN\n",
    "        print(\" Train on fold {}\".format(fold_i+1))\n",
    "\n",
    "        batch_size = 20000\n",
    "        iters = X_train.shape[0] // batch_size\n",
    "        if (X_train.shape[0] % batch_size > 0):\n",
    "            iters += 1\n",
    "\n",
    "        # for current task the number of epoches is 1    \n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch\", epoch + 1)\n",
    "            running_loss = 0\n",
    "            running_r2 = 0\n",
    "            with trange(iters) as t:\n",
    "                for i in t:\n",
    "                    X_batch, y_batch = get_batch(X_train,y_train, i)\n",
    "\n",
    "                    y_pred = model.forward(X_batch)\n",
    "                    loss = criterion.forward(y_batch, y_pred)\n",
    "                    dLdy = criterion.backward()\n",
    "                    model.backward(dLdy)\n",
    "\n",
    "                    running_loss += loss\n",
    "                    r2 = r2_score(y_batch, y_pred)\n",
    "                    running_r2 += r2\n",
    "\n",
    "                    t.set_postfix(mse=loss, r2=r2)\n",
    "\n",
    "            running_loss /= X_train.shape[0]/batch_size\n",
    "            running_r2 /= X_train.shape[0]/batch_size\n",
    "            print()\n",
    "            print(\"MSE = {}, R2 = {}\".format(running_loss, running_r2))\n",
    "\n",
    "        #TEST\n",
    "        print(\" Test on {} fold\".format(fold_i+1))\n",
    "\n",
    "        batch_size = 20000\n",
    "        iters = X_test.shape[0] // batch_size\n",
    "        if (X_test.shape[0] % batch_size > 0):\n",
    "            iters += 1\n",
    "\n",
    "        y_pred = np.zeros(y_test.shape)\n",
    "        for i in trange(iters):\n",
    "            X_batch, _ = get_batch(X_test,y_test, i)\n",
    "            y_pred[i*batch_size:(i+1)*batch_size] = model.forward(X_batch)\n",
    "\n",
    "        print()\n",
    "        rmses.append(rmse_score(y_test, y_pred))\n",
    "        r2s.append(r2_score(y_test, y_pred))\n",
    "        print(\"RMSE = {}, R2 = {}\".format(rmses[-1], r2s[-1]))\n",
    "        print()\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    epochs = 1\n",
    "    n_movies = 17770\n",
    "    n_users = len(user_ids)\n",
    "    k = 3\n",
    "   \n",
    "    compute_with_factorization_machine(epochs, n_movies, n_users, k)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
